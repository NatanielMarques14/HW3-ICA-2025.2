# HW3 - An√°lise Comparativa de Modelos de Classifica√ß√£o em Alta Dimensionalidade

Este reposit√≥rio cont√©m a implementa√ß√£o e an√°lise do **Homework 3** da disciplina de Intelig√™ncia Computacional Aplicada (ICA - 2025.2). O trabalho foca na an√°lise comparativa de modelos de classifica√ß√£o lineares e n√£o lineares aplicados a um conjunto de dados de alta dimensionalidade.

## üë• Autores
* **Jos√© Ferreira Lessa**
* **Victor Guedes Alves Texeira**
* **Nataniel Marques Viana Neto**
* **Matheus Rocha Gomes da Silva**

---

## üéØ Objetivo
O objetivo principal deste projeto √© estabelecer rela√ß√µes funcionais entre vari√°veis preditoras e uma vari√°vel resposta ("successful" vs "unsuccessful") em um cen√°rio de **alta dimensionalidade (252 vari√°veis preditoras)**. O estudo avalia o desempenho preditivo, custo computacional e o impacto da "maldi√ß√£o da dimensionalidade" em diferentes abordagens.

## üß† Modelos Implementados
Foram analisados tr√™s modelos distintos, cobrindo abordagens lineares e n√£o lineares:

1.  **Regress√£o Log√≠stica (Modelo Linear)**
    * **Configura√ß√£o:** Regulariza√ß√£o L2 (Ridge) com $C=1.0$.
    * **Caracter√≠sticas:** Simplicidade, interpretabilidade e efici√™ncia computacional.
    * **Justificativa:** Ponto de partida para estabelecer uma *baseline* e verificar a separabilidade linear dos dados.

2.  **K-Nearest Neighbors (KNN - N√£o Linear)**
    * **Configura√ß√£o:** Otimiza√ß√£o via Grid Search ($k=\{3,5,7,11\}$) e pondera√ß√£o (uniforme vs dist√¢ncia).
    * **Caracter√≠sticas:** Modelo baseado em inst√¢ncias (Lazy Learning).
    * **Desafio:** Alta sensibilidade √† dimensionalidade do espa√ßo de atributos.

3.  **Support Vector Machine (SVM - N√£o Linear)**
    * **Configura√ß√£o:** Kernel RBF (Radial Basis Function) e otimiza√ß√£o SMO.
    * **Caracter√≠sticas:** Maximiza√ß√£o de margem e uso do *kernel trick* para fronteiras complexas.
    * **Justificativa:** Capacidade de generaliza√ß√£o superior em espa√ßos complexos comparado ao KNN.

## ‚öôÔ∏è Metodologia
O pipeline de processamento dos dados seguiu as etapas abaixo:
* **Pr√©-processamento:** Padroniza√ß√£o das vari√°veis utilizando `StandardScaler` (m√©dia zero e vari√¢ncia unit√°ria).
* **Divis√£o dos Dados:** * Treino: 8.190 amostras.
    * Teste: 518 amostras.
* **Valida√ß√£o:** Valida√ß√£o cruzada (*k-fold cross-validation* com $k=5$) para ajuste de hiperpar√¢metros.
* **M√©tricas:** Acur√°cia, Matriz de Confus√£o, Precis√£o, Revoca√ß√£o e Especificidade.

## üìä Resultados Obtidos

A tabela abaixo resume a acur√°cia obtida por cada modelo no conjunto de teste:

| Modelo | Acur√°cia | Observa√ß√µes |
| :--- | :---: | :--- |
| **Regress√£o Log√≠stica** | **83.98%** | Melhor desempenho geral. Bom equil√≠brio entre vi√©s e vari√¢ncia. |
| **SVM (Kernel RBF)** | 81.08% | Competitivo, com fronteira de decis√£o eficiente, mas mais complexo. |
| **KNN** | 64.00% | Desempenho inferior devido √† alta dimensionalidade (*Curse of Dimensionality*). |

